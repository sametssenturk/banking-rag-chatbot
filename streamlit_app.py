
import streamlit as st
import os
from sentence_transformers import SentenceTransformer
import chromadb
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.chains import RetrievalQA
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate

st.set_page_config(
    page_title="Banking RAG Chatbot",
    page_icon="ğŸ¦",
    layout="wide"
)

# Gemini API Key - Streamlit secrets veya ortam deÄŸiÅŸkeninden al
GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY", os.environ.get("GOOGLE_API_KEY", ""))

# RAG sistemini baÅŸlat (sadece ilk Ã§alÄ±ÅŸtÄ±rmada)
@st.cache_resource
def load_rag_system():
    try:
        # ChromaDB path kontrolÃ¼
        chroma_db_path = "./chroma_db"
        
        # ChromaDB'yi yÃ¼kle
        chroma_client = chromadb.PersistentClient(path=chroma_db_path)
        
        # Koleksiyon var mÄ± kontrol et
        try:
            collections = chroma_client.list_collections()
            if not any(col.name == "banking77_collection" for col in collections):
                st.error("âŒ ChromaDB koleksiyonu bulunamadÄ±! LÃ¼tfen Ã¶nce Kaggle notebook'u Ã§alÄ±ÅŸtÄ±rarak vektÃ¶r veritabanÄ±nÄ± oluÅŸturun.")
                return None
        except Exception as e:
            st.error(f"âŒ ChromaDB koleksiyonu kontrol edilemedi: {str(e)}")
            return None
        
        # Embeddings
        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-mpnet-base-v2"
        )
        
        # Vector store
        vectorstore = Chroma(
            client=chroma_client,
            collection_name="banking77_collection",
            embedding_function=embeddings
        )
        
        # LLM
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            temperature=0.3,
            google_api_key=GOOGLE_API_KEY
        )
        
        # Prompt
        prompt_template = """
You are a helpful banking assistant. Use the context below to answer the question accurately and professionally.

If the question is related to the provided context, give a detailed and helpful answer.
If the question is not related to banking or the context, politely say that you can only help with banking-related questions.

Context:
{context}

Question: {question}

Answer:
"""
        
        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )
        
        # RAG Chain
        rag_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
            chain_type_kwargs={"prompt": PROMPT},
            return_source_documents=True
        )
        
        return rag_chain
    except Exception as e:
        st.error(f"RAG sistemi yÃ¼klenirken hata: {str(e)}")
        return None

# RAG sistemini yÃ¼kle
rag_chain = load_rag_system()

# BaÅŸlÄ±k ve aÃ§Ä±klama
st.title("ğŸ¦ Banking RAG Chatbot")
st.markdown("""
Bu chatbot, **Banking77** veri seti ve **RAG (Retrieval-Augmented Generation)** teknolojisi kullanÄ±larak geliÅŸtirilmiÅŸtir.
BankacÄ±lÄ±kla ilgili sorularÄ±nÄ±zÄ± **Ä°ngilizce** olarak sorabilirsiniz.
""")

# Sidebar - Bilgilendirme
with st.sidebar:
    st.header("â„¹ï¸ HakkÄ±nda")
    st.info("""
    **Teknolojiler:**
    - ğŸ¤– Gemini API (LLM)
    - ğŸ§  Sentence Transformers (Embedding)
    - ğŸ’¾ ChromaDB (Vector DB)
    - ğŸ”— LangChain (RAG Framework)
    - ğŸ¨ Streamlit (Web UI)
    """)
    
    st.header("ğŸ’¡ Ã–rnek Sorular")
    example_questions = [
        "I lost my credit card, what should I do?",
        "How can I transfer money to another account?",
        "What are the fees for international transactions?",
        "How do I check my account balance?",
        "Can I change my PIN number?"
    ]
    
    for q in example_questions:
        if st.button(q, key=q, use_container_width=True):
            # Ã–rnek soruyu chat input'a yaz
            st.session_state.example_question = q

# Chat geÃ§miÅŸini sakla
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ã–nceki mesajlarÄ± gÃ¶ster
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "sources" in message and message["sources"]:
            with st.expander("ğŸ“š Kaynak DokÃ¼manlar"):
                for i, doc in enumerate(message["sources"], 1):
                    st.markdown(f"**{i}.** {doc}")

# KullanÄ±cÄ± input'u
prompt = st.chat_input("BankacÄ±lÄ±k sorunuzu buraya yazÄ±n...")

# EÄŸer Ã¶rnek soru tÄ±klandÄ±ysa onu kullan
if "example_question" in st.session_state and st.session_state.example_question:
    prompt = st.session_state.example_question
    st.session_state.example_question = None

if prompt:
    # KullanÄ±cÄ± mesajÄ±nÄ± ekle ve gÃ¶ster
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Chatbot yanÄ±tÄ±
    with st.chat_message("assistant"):
        if rag_chain is None:
            error_msg = "âŒ RAG sistemi yÃ¼klenemedi. LÃ¼tfen API anahtarÄ±nÄ±zÄ± kontrol edin."
            st.error(error_msg)
            st.session_state.messages.append({"role": "assistant", "content": error_msg})
        else:
            with st.spinner("ğŸ¤” DÃ¼ÅŸÃ¼nÃ¼yorum..."):
                try:
                    # RAG sisteminden yanÄ±t al
                    result = rag_chain({"query": prompt})
                    response = result['result']
                    sources = [doc.page_content for doc in result.get('source_documents', [])]
                    
                    # YanÄ±tÄ± gÃ¶ster
                    st.markdown(response)
                    
                    # Kaynak dokÃ¼manlarÄ± gÃ¶ster
                    if sources:
                        with st.expander("ğŸ“š Kaynak DokÃ¼manlar"):
                            for i, doc in enumerate(sources, 1):
                                st.markdown(f"**{i}.** {doc}")
                    
                    # YanÄ±tÄ± geÃ§miÅŸe ekle
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": response,
                        "sources": sources
                    })
                    
                except Exception as e:
                    error_msg = f"âŒ ÃœzgÃ¼nÃ¼m, bir hata oluÅŸtu: {str(e)}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})

# Sohbeti temizle butonu
if st.sidebar.button("ğŸ—‘ï¸ Sohbeti Temizle", use_container_width=True):
    st.session_state.messages = []
    st.rerun()

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center'>
    <p>Developed with â¤ï¸ using LangChain & Gemini API</p>
</div>
""", unsafe_allow_html=True)
