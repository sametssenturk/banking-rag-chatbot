{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a8de222",
   "metadata": {},
   "source": [
    "# ğŸ¦ Banking-RAG Chatbot Projesi\n",
    "\n",
    "## Proje TanÄ±tÄ±mÄ±\n",
    "\n",
    "Bu projede, **Banking77** veri setini kullanarak, banka mÃ¼ÅŸterilerinin sorularÄ±na akÄ±llÄ±ca cevap verebilen bir **RAG (Retrieval-Augmented Generation)** tabanlÄ± chatbot geliÅŸtireceÄŸiz.\n",
    "\n",
    "### ğŸ¯ RAG Mimarisi Nedir?\n",
    "\n",
    "RAG, bilgi getirme (retrieval) ve Ã¼retken dil modeli (generation) teknolojilerini birleÅŸtiren bir mimaridir:\n",
    "\n",
    "1. **Retrieval (Bilgi Getirme):** KullanÄ±cÄ±nÄ±n sorusuyla ilgili en alakalÄ± dokÃ¼manlar vektÃ¶r veritabanÄ±ndan getirilir\n",
    "2. **Augmentation (ZenginleÅŸtirme):** Getirilen bilgiler prompt iÃ§ine eklenir\n",
    "3. **Generation (Ãœretim):** LLM bu bilgileri kullanarak doÄŸru ve tutarlÄ± yanÄ±t Ã¼retir\n",
    "\n",
    "### ğŸ› ï¸ KullanÄ±lacak Teknolojiler\n",
    "\n",
    "- **LLM (Generative Model):** Gemini API (gemini-2.5-flash)\n",
    "- **Embedding Model:** sentence-transformers/all-mpnet-base-v2\n",
    "- **VektÃ¶r VeritabanÄ±:** ChromaDB\n",
    "- **RAG Framework:** LangChain\n",
    "- **Veri Seti:** PolyAI/banking77 (Hugging Face)\n",
    "- **Web ArayÃ¼zÃ¼:** Streamlit\n",
    "\n",
    "### ğŸ“Š Veri Seti HakkÄ±nda\n",
    "\n",
    "Banking77 veri seti, 13.083 mÃ¼ÅŸteri sorusunu iÃ§eren ve 77 farklÄ± niyeti (intent) kapsayan bir veri setidir. BankacÄ±lÄ±k alanÄ±nda yaygÄ±n mÃ¼ÅŸteri sorgularÄ±nÄ± iÃ§erir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0e637",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Gerekli KÃ¼tÃ¼phanelerin Kurulumu\n",
    "\n",
    "Bu bÃ¶lÃ¼mde projemiz iÃ§in gerekli tÃ¼m Python kÃ¼tÃ¼phanelerini yÃ¼klÃ¼yoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eaeb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kÃ¼tÃ¼phaneleri yÃ¼kle\n",
    "\n",
    "# LangChain\n",
    "%pip install -q langchain==0.1.16 langchain-community==0.0.36 langchain-google-genai==0.0.8\n",
    "\n",
    "# Vector DB\n",
    "%pip install -q chromadb==0.4.24\n",
    "\n",
    "# Embeddings / ML\n",
    "%pip install -q sentence-transformers==2.7.0 transformers==4.41.2\n",
    "\n",
    "# PyTorch\n",
    "%pip install -q torch==2.2.2 \n",
    "\n",
    "# Google AI\n",
    "%pip install -q google-generativeai==0.3.2\n",
    "\n",
    "# Data Processing\n",
    "%pip install -q pandas==2.2.2 numpy==1.26.4\n",
    "\n",
    "print(\"âœ… TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cbb6cc",
   "metadata": {},
   "source": [
    "## ğŸ“š KÃ¼tÃ¼phaneleri Ä°Ã§e Aktar\n",
    "\n",
    "Projede kullanacaÄŸÄ±mÄ±z tÃ¼m kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±yoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temel kÃ¼tÃ¼phaneler\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Veri iÅŸleme\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Embedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ChromaDB\n",
    "import chromadb\n",
    "\n",
    "# LangChain\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Gemini API\n",
    "import google.generativeai as genai\n",
    "\n",
    "print(\"âœ… TÃ¼m kÃ¼tÃ¼phaneler baÅŸarÄ±yla iÃ§e aktarÄ±ldÄ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f347e6",
   "metadata": {},
   "source": [
    "## ğŸ”‘ API AnahtarÄ±nÄ± Ayarla\n",
    "\n",
    "Gemini API'yi kullanabilmek iÃ§in API anahtarÄ±nÄ±zÄ± buraya girmeniz gerekiyor.\n",
    "\n",
    "**Not:** API anahtarÄ±nÄ±zÄ± [Google AI Studio](https://makersuite.google.com/app/apikey) adresinden alabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4182ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini API anahtarÄ±nÄ± buraya girin\n",
    "# API anahtarÄ±nÄ±zÄ± https://makersuite.google.com/app/apikey adresinden alabilirsiniz\n",
    "GOOGLE_API_KEY = \"YOUR_API_KEY_HERE\"  # Buraya kendi API anahtarÄ±nÄ±zÄ± girin\n",
    "\n",
    "# Ortam deÄŸiÅŸkenine ata\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "# Gemini API'yi yapÄ±landÄ±r\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "print(\"âœ… API anahtarÄ± baÅŸarÄ±yla ayarlandÄ±!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c92894",
   "metadata": {},
   "source": [
    "## ğŸ“Š Veri Seti YÃ¼kleme ve Ä°nceleme\n",
    "\n",
    "Banking77 veri setini Hugging Face'den yÃ¼klÃ¼yoruz ve iÃ§eriÄŸini inceliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64147695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banking77 veri setini CSV olarak yÃ¼kle (sadece pandas kullan)\n",
    "print(\"â³ Veri seti yÃ¼kleniyor...\")\n",
    "\n",
    "try:\n",
    "    # Kaynak CSV'ler\n",
    "    train_url = \"https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/train.csv\"\n",
    "    test_url = \"https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/test.csv\"\n",
    "\n",
    "    # CSV'leri yÃ¼kle\n",
    "    train_df = pd.read_csv(train_url)\n",
    "    test_df = pd.read_csv(test_url)\n",
    "\n",
    "    # Kolon isimlerini dÃ¼zelt (category -> label) ve string'e Ã§evir\n",
    "    if 'category' in train_df.columns:\n",
    "        train_df = train_df.rename(columns={'category': 'label'})\n",
    "    if 'category' in test_df.columns:\n",
    "        test_df = test_df.rename(columns={'category': 'label'})\n",
    "\n",
    "    # Label'larÄ±n string olduÄŸundan emin ol\n",
    "    train_df['label'] = train_df['label'].astype(str)\n",
    "    test_df['label'] = test_df['label'].astype(str)\n",
    "\n",
    "    # Basit Ã¶zet\n",
    "    print(\"âœ… Veri seti baÅŸarÄ±yla yÃ¼klendi!\")\n",
    "    print(f\"ğŸ“Š Train set: {len(train_df)} Ã¶rnek\")\n",
    "    print(f\"ğŸ“Š Test set: {len(test_df)} Ã¶rnek\")\n",
    "    print(f\"ğŸ“‹ Kolonlar: {list(train_df.columns)}\")\n",
    "    print(f\"ğŸ·ï¸ Toplam intent sayÄ±sÄ±: {train_df['label'].nunique()}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Veri seti yÃ¼klenirken hata oluÅŸtu: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa71fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ä°lk 10 Ã¶rneÄŸi incele\n",
    "print(\"\\nğŸ“– Ä°lk 10 Ã¶rnek:\")\n",
    "print(train_df.head(10))\n",
    "\n",
    "# Ä°statistiksel bilgiler\n",
    "print(f\"\\nğŸ“ˆ Benzersiz intent (niyet) sayÄ±sÄ±: {train_df['label'].nunique()}\")\n",
    "print(f\"\\nğŸ·ï¸ Ä°lk 10 intent daÄŸÄ±lÄ±mÄ±:\")\n",
    "print(train_df['label'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–rnek sorgularÄ± gÃ¶ster\n",
    "print(\"\\nğŸ’¬ Ã–rnek MÃ¼ÅŸteri SorgularÄ±:\")\n",
    "print(\"=\" * 80)\n",
    "for i, text in enumerate(train_df['text'].head(10), 1):\n",
    "    print(f\"{i}. {text}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c7d4f",
   "metadata": {},
   "source": [
    "## ğŸ§  Embedding Modelinin YÃ¼klenmesi ve KullanÄ±mÄ±\n",
    "\n",
    "Sentence Transformers kÃ¼tÃ¼phanesinden **all-mpnet-base-v2** modelini yÃ¼klÃ¼yoruz. Bu model, metinleri 768 boyutlu vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9969b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding modelini yÃ¼kle\n",
    "print(\"â³ Embedding modeli yÃ¼kleniyor...\")\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "print(\"âœ… Embedding modeli baÅŸarÄ±yla yÃ¼klendi!\")\n",
    "\n",
    "# Model hakkÄ±nda bilgi\n",
    "print(f\"\\nğŸ“ Embedding boyutu: {embedding_model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907dd48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ã–rnek metin iÃ§in embedding oluÅŸtur\n",
    "ornek_metin = \"I lost my credit card, what should I do?\"\n",
    "ornek_embedding = embedding_model.encode(ornek_metin)\n",
    "\n",
    "print(f\"ğŸ“ Ã–rnek Metin: {ornek_metin}\")\n",
    "print(f\"\\nğŸ“Š Embedding VektÃ¶r Boyutu: {ornek_embedding.shape}\")\n",
    "print(f\"\\nğŸ”¢ Ä°lk 10 embedding deÄŸeri:\")\n",
    "print(ornek_embedding[:10])\n",
    "print(f\"\\nğŸ“ˆ VektÃ¶r istatistikleri:\")\n",
    "print(f\"   - Minimum: {ornek_embedding.min():.4f}\")\n",
    "print(f\"   - Maksimum: {ornek_embedding.max():.4f}\")\n",
    "print(f\"   - Ortalama: {ornek_embedding.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BirkaÃ§ farklÄ± sorgu iÃ§in embedding oluÅŸtur ve benzerlik hesapla (numpy ile)\n",
    "\n",
    "def cosine_sim_np(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    a = a.astype(np.float32)\n",
    "    b = b.astype(np.float32)\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / denom)\n",
    "\n",
    "test_sorulari = [\n",
    "    \"I lost my credit card\",\n",
    "    \"How can I transfer money?\",\n",
    "    \"What is my account balance?\"\n",
    "]\n",
    "\n",
    "test_embeddings = embedding_model.encode(test_sorulari)\n",
    "\n",
    "print(\"\\nğŸ” Test SorgularÄ± ve Embedding BoyutlarÄ±:\")\n",
    "for i, (soru, emb) in enumerate(zip(test_sorulari, test_embeddings), 1):\n",
    "    print(f\"{i}. '{soru}' -> Boyut: {emb.shape}\")\n",
    "\n",
    "# Ä°lk soru ile diÄŸerleri arasÄ±ndaki benzerlik\n",
    "print(\"\\nğŸ“ Cosine Benzerlik SkorlarÄ± (1. soru ile karÅŸÄ±laÅŸtÄ±rma):\")\n",
    "base = test_embeddings[0]\n",
    "for i, soru in enumerate(test_sorulari[1:], 2):\n",
    "    benzerlik = cosine_sim_np(base, test_embeddings[i-1])\n",
    "    print(f\"   Soru {i}: {benzerlik:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a1898c",
   "metadata": {},
   "source": [
    "## ğŸ’¾ ChromaDB VeritabanÄ± Kurulumu\n",
    "\n",
    "TÃ¼m Banking77 veri setindeki metinleri embedding'lere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼p ChromaDB'ye kaydediyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9c0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TÃ¼m metinler iÃ§in embedding oluÅŸtur\n",
    "print(\"â³ TÃ¼m veri seti iÃ§in embedding'ler oluÅŸturuluyor...\")\n",
    "print(f\"ğŸ“Š Toplam iÅŸlenecek metin sayÄ±sÄ±: {len(train_df)}\")\n",
    "\n",
    "# Metinleri al\n",
    "all_texts = train_df['text'].tolist()\n",
    "all_labels = train_df['label'].astype(str).tolist()\n",
    "\n",
    "# Batch halinde embedding oluÅŸtur (daha hÄ±zlÄ±)\n",
    "batch_size = 32\n",
    "all_embeddings = embedding_model.encode(\n",
    "    all_texts,\n",
    "    batch_size=batch_size,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# NumPy -> list\n",
    "all_embeddings = np.asarray(all_embeddings)\n",
    "\n",
    "print(f\"\\nâœ… {len(all_embeddings)} adet embedding baÅŸarÄ±yla oluÅŸturuldu!\")\n",
    "print(f\"ğŸ“ Embedding matrisi boyutu: {all_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82070784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChromaDB client oluÅŸtur\n",
    "print(\"â³ ChromaDB baÅŸlatÄ±lÄ±yor...\")\n",
    "\n",
    "# Streamlit uygulamasÄ± ile aynÄ± yol ve isimleri kullan\n",
    "chroma_db_path = \"./chroma_db\"\n",
    "collection_name = \"banking77_collection\"\n",
    "\n",
    "# Persistent Client\n",
    "chroma_client = chromadb.PersistentClient(path=chroma_db_path)\n",
    "\n",
    "# Varsa eski koleksiyonu sil (opsiyonel gÃ¼venli)\n",
    "try:\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "    print(f\"ğŸ—‘ï¸ Eski '{collection_name}' koleksiyonu silindi.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Yeni koleksiyon oluÅŸtur\n",
    "collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"description\": \"Banking77 dataset embeddings\"}\n",
    ")\n",
    "\n",
    "print(f\"âœ… '{collection_name}' koleksiyonu oluÅŸturuldu!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding'leri ChromaDB'ye ekle\n",
    "print(\"â³ Embedding'ler ChromaDB'ye ekleniyor...\")\n",
    "\n",
    "batch_size = 100\n",
    "n = len(all_texts)\n",
    "for i in range(0, n, batch_size):\n",
    "    batch_end = min(i + batch_size, n)\n",
    "    collection.add(\n",
    "        embeddings=all_embeddings[i:batch_end].tolist(),\n",
    "        documents=all_texts[i:batch_end],\n",
    "        ids=[f\"id_{j}\" for j in range(i, batch_end)],\n",
    "        metadatas=[{\"label\": all_labels[j]} for j in range(i, batch_end)]\n",
    "    )\n",
    "    if (i // batch_size) % 10 == 0:\n",
    "        print(f\"   â³ {batch_end}/{n} embedding eklendi...\")\n",
    "\n",
    "print(f\"\\nâœ… Toplam {n} embedding baÅŸarÄ±yla ChromaDB'ye eklendi!\")\n",
    "print(f\"ğŸ“Š Koleksiyon bilgileri:\")\n",
    "print(f\"   - Ä°sim: {collection.name}\")\n",
    "print(f\"   - Toplam kayÄ±t: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347623d",
   "metadata": {},
   "source": [
    "## ğŸ” ChromaDB Sorgulama Testi\n",
    "\n",
    "Basit bir sorgulama Ã¶rneÄŸi ile sistemin Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± test ediyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e01cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sorgusu\n",
    "test_sorgu = \"I lost my card\"\n",
    "\n",
    "# Sorgu iÃ§in embedding oluÅŸtur\n",
    "sorgu_embedding = embedding_model.encode([test_sorgu])\n",
    "\n",
    "# En yakÄ±n 5 sonucu getir\n",
    "sonuclar = collection.query(\n",
    "    query_embeddings=sorgu_embedding.tolist(),\n",
    "    n_results=5\n",
    ")\n",
    "\n",
    "print(f\"ğŸ” Test Sorgusu: '{test_sorgu}'\")\n",
    "print(f\"\\nğŸ“‹ En yakÄ±n {len(sonuclar['documents'][0])} sonuÃ§:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, (doc, distance) in enumerate(zip(sonuclar['documents'][0], sonuclar['distances'][0]), 1):\n",
    "    print(f\"\\n{i}. SonuÃ§:\")\n",
    "    print(f\"   ğŸ“ Metin: {doc}\")\n",
    "    print(f\"   ğŸ“ UzaklÄ±k Skoru: {distance:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71318dd4",
   "metadata": {},
   "source": [
    "## ğŸ§© RAG Pipeline Kurulumu\n",
    "\n",
    "LangChain kullanarak tam bir RAG pipeline'Ä± oluÅŸturuyoruz. Bu pipeline:\n",
    "1. KullanÄ±cÄ± sorgusunu alÄ±r\n",
    "2. ChromaDB'den en alakalÄ± dokÃ¼manlarÄ± getirir\n",
    "3. Bu bilgileri Gemini API'ye gÃ¶nderir\n",
    "4. AnlamlÄ± ve doÄŸru yanÄ±t Ã¼retir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain iÃ§in embedding fonksiyonu oluÅŸtur\n",
    "print(\"â³ LangChain bileÅŸenleri hazÄ±rlanÄ±yor...\")\n",
    "\n",
    "# HuggingFace embeddings wrapper\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "# ChromaDB'yi LangChain vector store olarak yapÄ±landÄ±r\n",
    "vectorstore = Chroma(\n",
    "    client=chroma_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embeddings\n",
    ")\n",
    "\n",
    "print(\"âœ… Vector store hazÄ±r!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f29b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini LLM modelini yapÄ±landÄ±r\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.3,\n",
    "    google_api_key=GOOGLE_API_KEY,\n",
    ")\n",
    "\n",
    "print(\"âœ… Gemini LLM modeli hazÄ±r!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c222799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt ÅŸablonu oluÅŸtur\n",
    "prompt_template = \"\"\"\n",
    "You are a helpful banking assistant. Use the context below to answer the question accurately and professionally.\n",
    "\n",
    "If the question is related to the provided context, give a detailed and helpful answer.\n",
    "If the question is not related to banking or the context, politely say that you can only help with banking-related questions.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "print(\"âœ… Prompt ÅŸablonu oluÅŸturuldu!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097ccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG chain'i oluÅŸtur\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG Pipeline baÅŸarÄ±yla oluÅŸturuldu!\")\n",
    "print(\"\\nğŸ“‹ Pipeline Ã¶zellikleri:\")\n",
    "print(\"   - Retrieval sayÄ±sÄ±: 3 en alakalÄ± dokÃ¼man\")\n",
    "print(\"   - LLM modeli: gemini-2.5-flash\")\n",
    "print(\"   - Embedding modeli: all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ac5033",
   "metadata": {},
   "source": [
    "## ğŸ§ª RAG Pipeline Test\n",
    "\n",
    "OluÅŸturduÄŸumuz RAG sistemini test ediyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c74fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test fonksiyonu\n",
    "def test_rag_system(question):\n",
    "    \"\"\"\n",
    "    RAG sistemini test etmek iÃ§in yardÄ±mcÄ± fonksiyon\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"â“ SORU: {question}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # RAG chain'den yanÄ±t al\n",
    "    result = rag_chain({\"query\": question})\n",
    "    \n",
    "    # YanÄ±tÄ± gÃ¶ster\n",
    "    print(f\"\\nğŸ’¡ CEVAP:\\n{result['result']}\")\n",
    "    \n",
    "    # Kaynak dokÃ¼manlarÄ± gÃ¶ster\n",
    "    print(f\"\\nğŸ“š KAYNAK DOKÃœMANLAR:\")\n",
    "    for i, doc in enumerate(result['source_documents'], 1):\n",
    "        print(f\"\\n   {i}. {doc.page_content}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\\n\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"âœ… Test fonksiyonu hazÄ±r!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cbc05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sorusu 1\n",
    "test_rag_system(\"I lost my credit card, what should I do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd2d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sorusu 2\n",
    "test_rag_system(\"How can I transfer money to another account?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sorusu 3\n",
    "test_rag_system(\"What are the fees for international transactions?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb38ff",
   "metadata": {},
   "source": [
    "## ğŸ“Š Performans DeÄŸerlendirme\n",
    "\n",
    "RAG sisteminin performansÄ±nÄ± deÄŸerlendirmek iÃ§in bazÄ± metrikler hesaplÄ±yoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6283df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Performans testi\n",
    "test_questions = [\n",
    "    \"I lost my card\",\n",
    "    \"How to transfer money?\",\n",
    "    \"What is my balance?\",\n",
    "    \"How to activate card?\",\n",
    "    \"ATM withdrawal limit\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª Performans testi baÅŸlatÄ±lÄ±yor...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_time = 0\n",
    "results = []\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\nğŸ“ Test {i}/{len(test_questions)}: {question}\")\n",
    "    \n",
    "    # Zaman Ã¶lÃ§\n",
    "    start_time = time.time()\n",
    "    result = rag_chain({\"query\": question})\n",
    "    end_time = time.time()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    total_time += elapsed_time\n",
    "    \n",
    "    print(f\"   â±ï¸ YanÄ±t sÃ¼resi: {elapsed_time:.2f} saniye\")\n",
    "    print(f\"   ğŸ“„ Kaynak dokÃ¼man sayÄ±sÄ±: {len(result['source_documents'])}\")\n",
    "    \n",
    "    results.append({\n",
    "        'question': question,\n",
    "        'time': elapsed_time,\n",
    "        'sources': len(result['source_documents'])\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nğŸ“ˆ PERFORMANS Ã–ZETÄ°:\")\n",
    "print(f\"   â±ï¸ Toplam sÃ¼re: {total_time:.2f} saniye\")\n",
    "print(f\"   ğŸ“Š Ortalama yanÄ±t sÃ¼resi: {total_time/len(test_questions):.2f} saniye\")\n",
    "print(f\"   âœ… BaÅŸarÄ±yla tamamlanan test: {len(results)}/{len(test_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8dd808",
   "metadata": {},
   "source": [
    "## ğŸ¯ SonuÃ§ ve Ã–neriler\n",
    "\n",
    "### âœ… Proje BaÅŸarÄ±yla TamamlandÄ±!\n",
    "\n",
    "Bu notebook'ta ÅŸunlarÄ± gerÃ§ekleÅŸtirdik:\n",
    "\n",
    "1. âœ… **Veri YÃ¼kleme:** Banking77 veri seti Hugging Face'den yÃ¼klendi\n",
    "2. âœ… **Embedding OluÅŸturma:** 13,000+ metin iÃ§in vektÃ¶r temsilleri oluÅŸturuldu\n",
    "3. âœ… **VektÃ¶r VeritabanÄ±:** ChromaDB ile semantik arama altyapÄ±sÄ± kuruldu\n",
    "4. âœ… **RAG Pipeline:** LangChain ve Gemini API ile tam bir RAG sistemi oluÅŸturuldu\n",
    "5. âœ… **Web ArayÃ¼zÃ¼:** Streamlit ile kullanÄ±cÄ± dostu bir chatbot arayÃ¼zÃ¼ geliÅŸtirildi\n",
    "\n",
    "### ğŸš€ GeliÅŸtirme Ã–nerileri:\n",
    "\n",
    "1. **Ã‡ok Dilli Destek:** TÃ¼rkÃ§e sorgularÄ± da destekleyecek ÅŸekilde geniÅŸletilebilir\n",
    "2. **Fine-tuning:** Gemini modeli bankacÄ±lÄ±k domaininde fine-tune edilebilir\n",
    "3. **KullanÄ±cÄ± Geri Bildirimi:** YanÄ±t kalitesi iÃ§in rating sistemi eklenebilir\n",
    "4. **Ã–nbellek MekanizmasÄ±:** SÄ±k sorulan sorular iÃ§in cache eklenebilir\n",
    "5. **Analytics Dashboard:** KullanÄ±m istatistikleri ve metrikler iÃ§in dashboard oluÅŸturulabilir\n",
    "\n",
    "### ğŸ“š Kaynaklar:\n",
    "\n",
    "- [Banking77 Dataset](https://huggingface.co/datasets/PolyAI/banking77)\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [Gemini API](https://ai.google.dev/)\n",
    "- [ChromaDB](https://www.trychroma.com/)\n",
    "- [Sentence Transformers](https://www.sbert.net/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73cd2b7",
   "metadata": {},
   "source": [
    "## ğŸ“¦ ChromaDB'yi ZIP'e DÃ¶nÃ¼ÅŸtÃ¼r ve Ä°ndir\n",
    "\n",
    "AÅŸaÄŸÄ±daki hÃ¼cre, `./chroma_db` klasÃ¶rÃ¼nÃ¼ `chroma_db.zip` olarak arÅŸivler. BÃ¶ylece GitHub'a kolayca ekleyebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2846c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_db klasÃ¶rÃ¼nÃ¼ zip'le\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "chroma_db_path = Path(\"./chroma_db\").resolve()\n",
    "zip_output = Path(\"./chroma_db.zip\").resolve()\n",
    "\n",
    "if not chroma_db_path.exists():\n",
    "    print(\"âŒ 'chroma_db' klasÃ¶rÃ¼ bulunamadÄ±. Ã–nce embedding oluÅŸturma hÃ¼crelerini Ã§alÄ±ÅŸtÄ±rÄ±n.\")\n",
    "else:\n",
    "    # Varsa eski zip'i sil\n",
    "    if zip_output.exists():\n",
    "        zip_output.unlink()\n",
    "    \n",
    "    # Windows uyumlu arÅŸivleme\n",
    "    archive_base = str(zip_output.with_suffix(''))  # \".../chroma_db\"\n",
    "    shutil.make_archive(archive_base, 'zip', root_dir=str(chroma_db_path))\n",
    "\n",
    "    size_mb = os.path.getsize(zip_output) / (1024 * 1024)\n",
    "    print(f\"âœ… ArÅŸiv oluÅŸturuldu: {zip_output}\")\n",
    "    print(f\"ğŸ“¦ Boyut: {size_mb:.2f} MB\")\n",
    "    print(\"â„¹ï¸ Bu dosyayÄ± GitHub deposuna ekleyebilirsiniz: 'chroma_db.zip'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
